{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tutorial for generating synthetic data\n",
    "We use a synthea OMOP dataset to demonstrate how to train cehrgpt and generate synthetic data.  "
   ],
   "id": "8c88cc91fd7377e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Install cehrgpt\n",
    "!pip install cehrgpt --constraint constraints.txt"
   ],
   "id": "9ac823473752a05d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install gdown",
   "id": "9a2f4683b424df90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!gdown --fuzzy \"https://drive.google.com/file/d/1k7-cZACaDNw8A1JRI37mfMAhEErxKaQJ/view?usp=share_link\"",
   "id": "4a4550e6d5a25e03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!mkdir omop_synthea\n",
    "!mkdir omop_synthea/cehrgpt\n",
    "!mkdir omop_synthea/dataset_prepared\n",
    "!mkdir omop_synthea/cehrgpt/syntheic_data"
   ],
   "id": "c4e0c83ad3f1d731",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!tar -xaf omop_synthea.tar.gz -C omop_synthea",
   "id": "32b71886fc86b214"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%env OMOP_DIR=omop_synthea\n",
    "%env CEHR_GPT_DATA_DIR=omop_synthea\n",
    "%env CEHR_GPT_MODEL_DIR=omop_synthea/cehrgpt\n",
    "%env SYNTHETIC_DATA_OUTPUT_DIR=omop_synthea/cehrgpt/syntheic_data"
   ],
   "id": "456b88a895c8edb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 1: Generate training data",
   "id": "7f0aa0492331b274"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import pyspark\n",
    "\n",
    "# Get paths\n",
    "python_path = subprocess.check_output(['which', 'python']).decode().strip()\n",
    "spark_home = pyspark.__file__.rsplit('/', 1)[0]\n",
    "\n",
    "# Set environment variables using magic commands\n",
    "%env SPARK_HOME=$spark_home\n",
    "%env PYSPARK_PYTHON=$python_path  \n",
    "%env PYSPARK_DRIVER_PYTHON=$python_path\n",
    "%env SPARK_WORKER_INSTANCES=1\n",
    "%env SPARK_WORKER_CORES=16\n",
    "%env SPARK_EXECUTOR_CORES=2\n",
    "%env SPARK_DRIVER_MEMORY=12g\n",
    "%env SPARK_EXECUTOR_MEMORY=12g\n",
    "%env SPARK_MASTER=local[64]\n",
    "\n",
    "# For paths, you'll still need to use os.environ for concatenation\n",
    "import os\n",
    "current_pythonpath = os.environ.get('PYTHONPATH', '')\n",
    "current_path = os.environ.get('PATH', '')\n",
    "os.environ['PYTHONPATH'] = f\"{spark_home}/python:{current_pythonpath}\"\n",
    "os.environ['PATH'] = f\"{spark_home}/bin:{current_path}\""
   ],
   "id": "5cea05c568dc18ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's see what the script receives as arguments\n",
    "!sh scripts/create_cehrgpt_pretraining_data.sh --input_folder {os.environ['OMOP_DIR']} --output_folder {os.environ['CEHR_GPT_DATA_DIR']} --start_date 1985-01-01"
   ],
   "id": "8614b89ee99cb125",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 2: Train CEHR-GPT",
   "id": "bfc185ed25e430cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "cmd = [\n",
    "    'python', '-u', '-m', 'cehrgpt.runners.hf_cehrgpt_pretrain_runner',\n",
    "    '--model_name_or_path', os.environ['CEHR_GPT_MODEL_DIR'],\n",
    "    '--tokenizer_name_or_path', os.environ['CEHR_GPT_MODEL_DIR'],\n",
    "    '--output_dir', os.environ['CEHR_GPT_MODEL_DIR'],\n",
    "    '--data_folder', f\"{os.environ['CEHR_GPT_DATA_DIR']}/patient_sequence/train\",\n",
    "    '--dataset_prepared_path', f\"{os.environ['CEHR_GPT_DATA_DIR']}/dataset_prepared\",\n",
    "    '--do_train', 'true',\n",
    "    '--seed', '42',\n",
    "    '--dataloader_num_workers', '16',\n",
    "    '--dataloader_prefetch_factor', '8',\n",
    "    '--hidden_size', '768',\n",
    "    '--num_hidden_layers', '12',\n",
    "    '--max_position_embeddings', '1024',\n",
    "    '--evaluation_strategy', 'epoch',\n",
    "    '--save_strategy', 'epoch',\n",
    "    '--sample_packing',\n",
    "    '--max_tokens_per_batch', '16384',\n",
    "    '--warmup_ratio', '0.01',\n",
    "    '--weight_decay', '0.01',\n",
    "    '--num_train_epochs', '50',\n",
    "    '--learning_rate', '0.0002',\n",
    "    '--use_early_stopping',\n",
    "    '--early_stopping_threshold', '0.001'\n",
    "]\n",
    "\n",
    "# Stream output in real-time\n",
    "process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, \n",
    "                          universal_newlines=True, bufsize=1)\n",
    "\n",
    "# Print output line by line as it comes\n",
    "for line in process.stdout:\n",
    "    print(line, end='')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# Wait for process to complete\n",
    "return_code = process.wait()\n",
    "print(f\"\\nCommand finished with return code: {return_code}\")"
   ],
   "id": "6a28d75173508517",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 3: Generate synthetic sequences",
   "id": "323cc4d06b3cb30d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "\n",
    "%env TRANSFORMERS_VERBOSITY=info\n",
    "%env CUDA_VISIBLE_DEVICES=\"0\"\n",
    "\n",
    "cmd = [\n",
    "    'python', '-u', '-m', 'cehrgpt.generation.generate_batch_hf_gpt_sequence',\n",
    "    '--model_folder', os.environ['CEHR_GPT_MODEL_DIR'],\n",
    "    '--tokenizer_folder', os.environ['CEHR_GPT_MODEL_DIR'],\n",
    "    '--output_folder', os.environ['SYNTHETIC_DATA_OUTPUT_DIR'],\n",
    "    '--num_of_patients', '128',\n",
    "    '--batch_size', '16',\n",
    "    '--buffer_size', '128',\n",
    "    '--context_window', '1024',\n",
    "    '--sampling_strategy', 'TopPStrategy',\n",
    "    '--top_p', '1.0',\n",
    "    '--temperature', '1.0',\n",
    "    '--repetition_penalty', '1.0',\n",
    "    '--epsilon_cutoff', '0.00',\n",
    "    '--demographic_data_path', f\"{os.environ['CEHR_GPT_DATA_DIR']}/patient_sequence/train\"\n",
    "]\n",
    "\n",
    "# Stream output in real-time\n",
    "process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, \n",
    "                          universal_newlines=True, bufsize=1)\n",
    "\n",
    "# Print output line by line as it comes\n",
    "for line in process.stdout:\n",
    "    print(line, end='')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# Wait for process to complete and get return code\n",
    "return_code = process.wait()\n",
    "print(f\"\\nCommand finished with return code: {return_code}\")"
   ],
   "id": "9a69a7e1b5bd353",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 4: Convert to OMOP Format",
   "id": "6a072d856c6186bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Set up the command\n",
    "cmd = [\n",
    "    'sh', 'scripts/omop_pipeline.sh',\n",
    "    f\"--patient-sequence-folder={os.environ['SYNTHETIC_DATA_OUTPUT_DIR']}/top_p10000/generated_sequences/\",\n",
    "    f\"--omop-folder={os.environ['SYNTHETIC_DATA_OUTPUT_DIR']}/top_p10000/restored_omop/\",\n",
    "    f\"--source-omop-folder={os.environ['OMOP_DIR']}\",\n",
    "    '--cpu-cores=10'\n",
    "]\n",
    "\n",
    "print(\"Running command:\")\n",
    "print(' '.join(cmd))\n",
    "print()\n",
    "\n",
    "# Stream output in real-time\n",
    "process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, \n",
    "                          universal_newlines=True, bufsize=1)\n",
    "\n",
    "# Print output line by line as it comes\n",
    "for line in process.stdout:\n",
    "    print(line, end='')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# Wait for process to complete\n",
    "return_code = process.wait()\n",
    "print(f\"\\nPipeline finished with return code: {return_code}\")"
   ],
   "id": "e354048f99120d76",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
